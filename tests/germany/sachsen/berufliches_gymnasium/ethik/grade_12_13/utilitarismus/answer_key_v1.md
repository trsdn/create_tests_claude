---
title: "Erwartungshorizont und Lösungen: Stundenarbeit Handlungsutilitarismus vs. Regelutilitarismus"
subject: Ethik/Philosophie
country: Germany
bundesland: Sachsen
school_type: Berufliches Gymnasium
klassenstufe: 12/13
document_type: "Lehrerkopie / Answer Key"
test_version: "v1"
language: de
created_by: Test Designer Agent
date_created: 2025-11-20
---

# Erwartungshorizont und Musterlösungen

## Stundenarbeit: Handlungsutilitarismus vs. Regelutilitarismus

**Berufliches Gymnasium Sachsen | Ethik/Philosophie | Klassenstufe 12/13**

**Lehrerkopie - Vertraulich**

---

## Allgemeine Bewertungshinweise

### Bewertungskriterien

**Inhaltliche Qualität (60-70%):**
- Fachliche Korrektheit der Darstellung
- Vollständigkeit der Argumentation
- Korrekte Verwendung philosophischer Fachbegriffe
- Systematische Anwendung der ethischen Theorien

**Formale Qualität (20-30%):**
- Strukturierte und klare Darstellung
- Logischer Argumentationsaufbau
- Sprachliche Präzision

**Reflexionstiefe (10-20%):**
- Kritisches Denken
- Eigenständige Gedankenführung
- Differenzierte Betrachtung
- Philosophische Tiefe

### Punktevergabe

- **Volle Punktzahl:** Alle geforderten Aspekte vollständig und korrekt behandelt, philosophisch fundiert argumentiert
- **Teilpunkte:** Aspekte teilweise behandelt oder mit kleineren Ungenauigkeiten, aber grundsätzlich richtige Richtung
- **Keine Punkte:** Wesentliche Fehler, fehlende Argumentation oder völlig am Thema vorbei

---

## Aufgabe 1a: Handlungsutilitaristische Analyse (9 Punkte)

### Erwartete Inhalte:

**Kernaspekte für volle Punktzahl:**

1. **Grundprinzip des Handlungsutilitarismus (3 Punkte):**
   - Konsequentialismus: Handlungen werden ausschließlich nach ihren Folgen bewertet (1 Punkt)
   - Nutzenmaximierung: Ziel ist die Maximierung des Gesamtnutzens/Gesamtwohls (1 Punkt)
   - Einzelfallbetrachtung: Jede Handlung wird individuell in ihrer konkreten Situation bewertet (1 Punkt)

2. **Anwendung auf den konkreten Fall (4 Punkte):**
   - Systematische Konsequenzenanalyse beider Optionen (2 Punkte):
     - Option A: 8 Personen gerettet + 2 Überlebende = 10 Überlebende, 1 Toter
     - Option B: 3 Personen gerettet, aber nur ca. 1-2 überleben an Ort A = 4-5 Überlebende, 6-7 Tote
   - Nutzenkalkulation und Vergleich (2 Punkte)

3. **Handlungsutilitaristische Empfehlung (2 Punkte):**
   - Eindeutige Empfehlung für Option A (1 Punkt)
   - Begründung: Maximiert die Anzahl der geretteten Leben (1 Punkt)

### Musterlösung:

Der Handlungsutilitarismus ist eine konsequentialistische Ethik, die Handlungen ausschließlich nach ihren Folgen bewertet. Das Grundprinzip lautet: Eine Handlung ist dann moralisch richtig, wenn sie in der konkreten Situation den größtmöglichen Nutzen bzw. das größte Gesamtwohl für alle Betroffenen bewirkt. Dabei wird jede Handlung einzeln betrachtet und durch eine systematische Abwägung aller positiven und negativen Konsequenzen beurteilt.

**Anwendung auf das Dilemma der Rettungsdrohne:**

Aus handlungsutilitaristischer Perspektive muss eine klare Nutzen-Schaden-Kalkulation durchgeführt werden:

- **Option A (Medikamente zu Unfallort A):** 8 Personen werden durch die Medikamente gerettet. An Unfallort B überleben 2 Personen auch ohne Medikamente, aber Person X stirbt. **Gesamtergebnis: 10 Überlebende, 1 Toter.**

- **Option B (Medikamente zu Unfallort B):** Person X überlebt durch die Medikamente, die anderen 2 an Ort B überleben ebenfalls. An Unfallort A überleben jedoch nur ca. 1-2 Personen ohne Medikamente (20% Überlebenschance). **Gesamtergebnis: 4-5 Überlebende, 6-7 Tote.**

**Handlungsutilitaristische Empfehlung:**

Ein Handlungsutilitarist würde eindeutig **Option A** empfehlen: Die Drohne sollte die Medikamente zu Unfallort A bringen. Diese Entscheidung maximiert die Anzahl der geretteten Leben. Option A führt zu 10 Überlebenden, während Option B nur 4-5 Überlebende zur Folge hätte. Aus rein konsequentialistischer Sicht ist die Handlung moralisch richtig, die das beste Gesamtergebnis erzielt – und das ist hier eindeutig Option A, die 5-6 Menschenleben mehr rettet.

### Bewertungshinweise:

- **9 Punkte:** Alle drei Kernaspekte vollständig behandelt, klare Kalkulation, eindeutige Empfehlung mit Begründung
- **6-8 Punkte:** Grundprinzip erklärt, Anwendung mit kleineren Lücken oder unvollständiger Kalkulation
- **3-5 Punkte:** Grundverständnis erkennbar, aber wesentliche Aspekte fehlen oder Anwendung oberflächlich
- **0-2 Punkte:** Grundprinzip nicht verstanden oder Handlungsutilitarismus nicht korrekt angewendet

---

## Aufgabe 1b: Regelutilitaristische Analyse (9 Punkte)

### Erwartete Inhalte:

**Kernaspekte für volle Punktzahl:**

1. **Grundprinzip des Regelutilitarismus (3 Punkte):**
   - Regelorientierung: Nicht einzelne Handlungen, sondern allgemeine Regeln werden nach ihren Konsequenzen bewertet (1 Punkt)
   - Langfristige Nutzenmaximierung: Ziel ist, Regeln zu etablieren, die langfristig das größte Gesamtwohl bewirken (1 Punkt)
   - Unterschied zum Handlungsutilitarismus: Fragt "Was wäre, wenn alle in solchen Situationen nach dieser Regel handeln würden?" statt "Was bringt diese konkrete Handlung?" (1 Punkt)

2. **Identifikation relevanter Regeln (3 Punkte):**
   - Regel "Maximiere die Anzahl der geretteten Leben" oder "Rette die meisten Menschen"
   - Regel "Behandle alle Menschen gleich" bzw. "Jedes Leben hat denselben Wert"
   - Systemischer Nutzen klarer, nachvollziehbarer Entscheidungsregeln für Rettungssysteme

3. **Regelutilitaristische Empfehlung mit Begründung (3 Punkte):**
   - Empfehlung (meist Option A, kann aber auch differenziert argumentiert werden)
   - Begründung des langfristigen Nutzens der Regel
   - Berücksichtigung systemischer Effekte

### Musterlösung:

Der Regelutilitarismus bewertet nicht einzelne Handlungen direkt nach ihren Konsequenzen, sondern etabliert allgemeine Handlungsregeln, die langfristig das größte Gesamtwohl für die Gesellschaft bewirken. Eine Handlung ist dann moralisch richtig, wenn sie einer Regel folgt, deren allgemeine Befolgung den besten Gesamtnutzen hätte. Der entscheidende Unterschied zum Handlungsutilitarismus liegt in der Frage: Statt "Was bringt diese konkrete Handlung hier und jetzt?" fragt der Regelutilitarist: "Was wäre, wenn jeder in solchen Situationen nach dieser Regel handeln würde?"

**Relevante Regeln im Kontext der Rettungsdrohne:**

1. **Regel "Maximiere die Anzahl der geretteten Leben":** Rettungssysteme sollten grundsätzlich so programmiert werden, dass sie die größtmögliche Anzahl von Menschen retten.

2. **Regel "Behandle jeden Patienten gleichwertig":** Jedes Menschenleben hat denselben Wert; es gibt keine Hierarchie zwischen den Opfern.

3. **Regel "Transparente und nachvollziehbare Entscheidungskriterien":** Rettungssysteme sollten nach klaren, öffentlich akzeptierten Kriterien entscheiden, um Vertrauen zu schaffen.

**Begründung des langfristigen Nutzens:**

Wenn die Regel "Maximiere die Anzahl geretteter Leben" allgemein befolgt wird, entstehen folgende langfristige positive Konsequenzen:
- Rettungssysteme arbeiten effizient und retten insgesamt mehr Menschen
- Die Regel ist klar, transparent und für die Öffentlichkeit nachvollziehbar
- Menschen können darauf vertrauen, dass Rettungssysteme rational und fair entscheiden
- Es entsteht keine willkürliche Hierarchisierung von Menschenleben

**Regelutilitaristische Empfehlung:**

Ein Regelutilitarist würde wahrscheinlich **Option A** empfehlen: Die Drohne sollte nach der Regel "Maximiere die Anzahl geretteter Leben" programmiert werden. Diese Regel führt langfristig zum größten Gesamtwohl, weil sie:
- Insgesamt die meisten Menschen rettet (nicht nur in diesem Fall, sondern systematisch)
- Klar und transparent ist
- Keine moralisch problematischen Unterscheidungen zwischen "wertvolleren" und "weniger wertvollen" Leben vornimmt
- Das Vertrauen in automatisierte Rettungssysteme stärkt

Die allgemeine Befolgung dieser Regel maximiert langfristig das Gesamtwohl der Gesellschaft, auch wenn in Einzelfällen schwierige Entscheidungen getroffen werden müssen.

### Bewertungshinweise:

- **9 Punkte:** Grundprinzip klar dargestellt, relevante Regeln identifiziert, langfristiger Nutzen überzeugend begründet, klare Empfehlung
- **6-8 Punkte:** Grundprinzip erklärt, Regeln identifiziert, kleinere Lücken in der Begründung oder Argumentation
- **3-5 Punkte:** Grundverständnis erkennbar, aber unvollständige Regelanalyse oder schwache Begründung des langfristigen Nutzens
- **0-2 Punkte:** Grundprinzip nicht verstanden oder Regelutilitarismus nicht korrekt angewendet

---

## Aufgabe 2: Kritische Bewertung (6 Punkte)

### Erwartete Inhalte:

**Je 1,5 Punkte pro gut erläuterter Stärke/Schwäche**

**Mögliche Stärken des Handlungsutilitarismus:**
- Flexibilität: Kann auf besondere Umstände der Situation eingehen
- Maximierung des unmittelbaren Nutzens: Fokus auf das beste konkrete Ergebnis
- Rationale Entscheidungsfindung: Klare Kalkulation führt zu eindeutigen Empfehlungen

**Mögliche Schwächen des Handlungsutilitarismus:**
- Fehlende Orientierung: Keine stabilen Regeln, jede Situation wird neu bewertet
- Quantifizierungsproblem: Nicht alles lässt sich in Zahlen fassen (Leiden, Lebenswert)
- Instrumentalisierung: Gefahr, Einzelne für das größere Wohl zu opfern

**Mögliche Stärken des Regelutilitarismus:**
- Verlässlichkeit: Klare Regeln schaffen Vertrauen und Orientierung
- Langfristige Perspektive: Berücksichtigt systemische Effekte über den Einzelfall hinaus
- Schutz vor Ad-hoc-Entscheidungen: Verhindert willkürliche Einzelfallentscheidungen

**Mögliche Schwächen des Regelutilitarismus:**
- Mangelnde Flexibilität: Starre Regeln können in Extremsituationen zu schlechten Ergebnissen führen
- Regelkonflikte: Was, wenn mehrere Regeln relevant sind und sich widersprechen?
- Schwer quantifizierbare langfristige Effekte: Systemischer Nutzen ist oft schwer zu beweisen

### Musterlösung (Beispiel):

**Handlungsutilitarismus:**

**Stärke:** Der Handlungsutilitarismus zeigt in diesem Fall seine Flexibilität und Fokussierung auf das beste unmittelbare Ergebnis. Er liefert eine klare, rationale Antwort: Die Drohne soll zu Unfallort A fliegen, weil dort die meisten Leben gerettet werden können. Diese pragmatische Herangehensweise maximiert das konkrete Gesamtwohl.

**Schwäche:** Der Handlungsutilitarismus bietet keine stabilen Orientierungsregeln für die Programmierung der Drohne. In jedem neuen Fall müsste neu kalkuliert werden. Zudem besteht die Gefahr, dass einzelne Personen (wie Person X) instrumentalisiert werden – ihr Leben wird geopfert, weil die Zahlen es so vorgeben, ohne Berücksichtigung möglicher qualitativer Unterschiede oder Rechte.

**Regelutilitarismus:**

**Stärke:** Der Regelutilitarismus bietet eine verlässliche, klare Regel für die Programmierung: "Maximiere die Anzahl geretteter Leben." Diese Regel schafft Transparenz und Vertrauen in das System. Menschen wissen, nach welchem Prinzip die Drohne entscheidet, und können dies nachvollziehen. Langfristig führt eine solche konsistente Regel zu einem höheren Gesamtnutzen.

**Schwäche:** In diesem speziellen Fall führt die Regel zum selben Ergebnis wie der Handlungsutilitarismus (Option A), aber man könnte sich Situationen vorstellen, in denen starre Regeln zu moralisch fragwürdigen Ergebnissen führen. Zudem ist unklar, welche Regel Vorrang hat, wenn mehrere Regeln (z.B. "Rette die meisten" vs. "Rette die am schwersten Verletzten") relevant sind.

### Bewertungshinweise:

- **6 Punkte:** Alle vier Aspekte (je eine Stärke und Schwäche pro Ansatz) klar benannt und überzeugend am Beispiel erläutert
- **4-5 Punkte:** Drei bis vier Aspekte behandelt, Erläuterung teilweise gelungen oder mit kleineren Ungenauigkeiten
- **2-3 Punkte:** Stärken/Schwächen genannt, aber wenig Bezug zum konkreten Fall oder oberflächliche Erläuterung
- **0-1 Punkte:** Wesentliche Fehler oder unzureichende Darstellung

---

## Aufgabe 3: Eigene Position (6 Punkte)

### Erwartete Inhalte:

**Hinweis:** Diese Aufgabe bewertet nicht die inhaltliche Position (welche Programmierung empfohlen wird), sondern die **Qualität der philosophischen Begründung**.

**Bewertungskriterien:**

1. **Klare Positionierung mit Begründung (2 Punkte):**
   - Eindeutige Empfehlung für die Programmierung
   - Explizite Stellungnahme, welcher utilitaristische Ansatz überzeugender ist

2. **Philosophische Tiefe der Argumentation (2 Punkte):**
   - Differenzierte Abwägung der verschiedenen ethischen Dimensionen
   - Berücksichtigung von Aspekten über den Utilitarismus hinaus (z.B. Deontologie, Verantwortungsethik, Menschenwürde)
   - Reflexion über Grenzen und Stärken der diskutierten Ansätze

3. **Eigenständigkeit und kritisches Denken (2 Punkte):**
   - Nicht bloße Wiederholung des Unterrichtsinhalts
   - Eigenständige Gedankenführung erkennbar
   - Kritische Reflexion und begründete Abwägung

### Mögliche Argumentationslinien (Beispiele - nicht abschließend):

**Position A: Für Option A / Handlungsutilitarismus**

"Ich würde die Drohne nach dem Prinzip 'Maximiere die Anzahl geretteter Leben' programmieren, also nach Option A. In diesem Fall überzeugt mich der handlungsutilitaristische Ansatz, weil die Zahlen so eindeutig sind: 10 Überlebende gegenüber 4-5 Überlebenden. Aus verantwortungsethischer Perspektive trägt der Programmierer Verantwortung für die Konsequenzen der Programmierung, und die Programmierung nach Option A rettet die meisten Leben. Allerdings sollte dies mit Transparenz verbunden sein: Die Öffentlichkeit muss wissen und akzeptieren, dass solche Systeme nach dem Prinzip der Nutzenmaximierung entscheiden. Zudem sollte sichergestellt werden, dass die Regel nicht zu diskriminierenden Praktiken führt (z.B. keine Bewertung nach Alter, Gesundheit oder sozialem Status)."

**Position B: Für regelutilitaristische Programmierung mit Nuancierung**

"Ich würde die Drohne regelutilitaristisch programmieren: 'Maximiere die Anzahl geretteter Leben, sofern keine anderen gravierenden Faktoren vorliegen.' Die Regel bietet Orientierung, Transparenz und langfristige Effizienz. Allerdings sollte die Regel Raum für Ausnahmen lassen, wenn qualitative Faktoren eine Rolle spielen (z.B. wenn eine der Gruppen Kinder enthält oder wenn die Verletzungen so unterschiedlich schwer sind, dass reine Zahlen nicht ausreichen). Über den Utilitarismus hinaus ist aus Sicht der Menschenwürde zu bedenken, dass eine rein quantitative Bewertung von Menschenleben ethisch problematisch ist. Die Programmierung sollte daher auch Mechanismen enthalten, die verhindern, dass Einzelne systematisch benachteiligt werden."

**Position C: Kritik beider Ansätze**

"Beide utilitaristischen Ansätze greifen in diesem Fall zu kurz, weil sie die Würde und die Rechte der Einzelnen nicht ausreichend berücksichtigen. Aus deontologischer Perspektive (Kant) könnte man argumentieren, dass jeder Mensch ein Recht auf Rettung hat und nicht instrumentalisiert werden darf. Eine rein utilitaristische Programmierung könnte dazu führen, dass Person X systematisch geopfert wird, nur weil sie in der Minderheit ist. Vielleicht sollte die Drohne stattdessen nach einem Zufallsprinzip oder nach dem Prinzip 'first come, first served' entscheiden, um die Gleichwertigkeit aller Menschenleben zu wahren. Oder es sollte eine Kombination sein: Primär Nutzenmaximierung, aber mit Schutzmechanismen für vulnerable Gruppen."

### Bewertungshinweise:

- **6 Punkte:** Klare, differenzierte Position mit philosophisch fundierter Begründung, Berücksichtigung verschiedener ethischer Perspektiven, eigenständiges kritisches Denken erkennbar
- **4-5 Punkte:** Klare Position mit Begründung, philosophische Ansätze werden herangezogen, noch ausbaufähig in Tiefe oder Differenziertheit
- **2-3 Punkte:** Position bezogen, aber Begründung bleibt oberflächlich oder beschränkt sich auf Wiederholung
- **0-1 Punkte:** Keine klare Position oder keine philosophische Begründung

---

## Gesamtbewertung

**Punkteverteilung:**

| Aufgabe | Maximale Punktzahl |
|---------|-------------------|
| Aufgabe 1a (Handlungsutilitarismus) | 9 Punkte |
| Aufgabe 1b (Regelutilitarismus) | 9 Punkte |
| Aufgabe 2 (Kritische Bewertung) | 6 Punkte |
| Aufgabe 3 (Eigene Position) | 6 Punkte |
| **GESAMT** | **30 Punkte** |

---

## Bewertungsskala (15-Punkte-System Sachsen Oberstufe)

| Erreichte Punkte | Notenpunkte | Note | Bewertung |
|-----------------|-------------|------|-----------|
| 29-30 | 15 | 1+ | Sehr gut |
| 27-28 | 14 | 1 | Sehr gut |
| 26 | 13 | 1- | Sehr gut |
| 24-25 | 12 | 2+ | Gut |
| 22-23 | 11 | 2 | Gut |
| 21 | 10 | 2- | Gut |
| 19-20 | 9 | 3+ | Befriedigend |
| 18 | 8 | 3 | Befriedigend |
| 17 | 7 | 3- | Befriedigend |
| 15-16 | 6 | 4+ | Ausreichend |
| 14 | 5 | 4 | Ausreichend |
| 12-13 | 4 | 4- | Ausreichend |
| 11 | 3 | 5+ | Mangelhaft |
| 9-10 | 2 | 5 | Mangelhaft |
| 8 | 1 | 5- | Mangelhaft |
| 0-7 | 0 | 6 | Ungenügend |

---

## Allgemeine Korrekturhinweise

**Positive Bewertung bei:**
- Verwendung korrekter philosophischer Fachbegriffe (Konsequentialismus, Nutzenmaximierung, Universalisierbarkeit, etc.)
- Strukturierte, logische Argumentation
- Systematische Anwendung der Theorien auf den konkreten Fall
- Eigenständige, kritische Reflexion
- Berücksichtigung verschiedener ethischer Perspektiven

**Abzüge bei:**
- Fehlender oder falscher Verwendung von Fachterminologie
- Unsystematischer, unklarer Argumentation
- Bloßer Wiedergabe ohne Anwendung auf den Fall
- Fehlender kritischer Reflexion
- Gravierenden sachlichen Fehlern

**Teilpunkte großzügig vergeben bei:**
- Richtiger Grundrichtung, aber unvollständiger Ausführung
- Kleinen Ungenauigkeiten bei ansonsten korrekter Darstellung
- Guten Ansätzen, die nicht vollständig zu Ende gedacht sind

**Ermutigung in Kommentaren:**
- Philosophie lebt von der Diskussion - verschiedene Positionen sind möglich
- Wichtig ist die Qualität der Begründung, nicht die Meinung
- Konstruktive Hinweise für Verbesserungen geben

---

## Zeitmanagement-Hinweise für Schüler (45 Minuten)

**Empfohlene Zeitverteilung:**
- Aufgabe 1a: 12 Minuten
- Aufgabe 1b: 12 Minuten
- Aufgabe 2: 10 Minuten
- Aufgabe 3: 10 Minuten
- Puffer/Überprüfung: 1 Minute

---

**Ende des Erwartungshorizonts**

**Viel Erfolg bei der Korrektur!**
