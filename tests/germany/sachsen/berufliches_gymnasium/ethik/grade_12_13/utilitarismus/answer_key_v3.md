---
title: "Erwartungshorizont und Lösungen: Stundenarbeit Handlungsutilitarismus vs. Regelutilitarismus"
subject: Ethik/Philosophie
country: Germany
bundesland: Sachsen
school_type: Berufliches Gymnasium
klassenstufe: 12/13
document_type: "Lehrerkopie / Answer Key"
test_version: "v3"
language: de
created_by: Test Designer Agent
date_created: 2025-11-20
session_id: "sess_20251120_222338"
test_id: "de-sn-bg-ethik-12-13-util-v3"
---

# Erwartungshorizont und Musterlösungen

## Stundenarbeit: Handlungsutilitarismus vs. Regelutilitarismus (Version 3)

**Berufliches Gymnasium Sachsen | Ethik/Philosophie | Klassenstufe 12/13**

**Lehrerkopie - Vertraulich**

---

## Allgemeine Bewertungshinweise

### Bewertungskriterien

**Inhaltliche Qualität (60-70%):**
- Fachliche Korrektheit der Darstellung
- Vollständigkeit der Argumentation
- Korrekte Verwendung philosophischer Fachbegriffe
- Systematische Anwendung der ethischen Theorien

**Formale Qualität (20-30%):**
- Strukturierte und klare Darstellung
- Logischer Argumentationsaufbau
- Sprachliche Präzision
- Orthografie und Grammatik

**Reflexionstiefe (10-20%):**
- Kritisches Denken
- Eigenständige Gedankenführung
- Differenzierte Betrachtung
- Philosophische Tiefe

### Punktevergabe

- **Volle Punktzahl:** Alle geforderten Aspekte vollständig und korrekt behandelt, philosophisch fundiert argumentiert
- **Teilpunkte:** Aspekte teilweise behandelt oder mit kleineren Ungenauigkeiten, aber grundsätzlich richtige Richtung
- **Keine Punkte:** Wesentliche Fehler, fehlende Argumentation oder völlig am Thema vorbei

---

## Aufgabe 1: Analyse aus handlungsutilitaristischer Perspektive (12 Punkte)

### Aufgabe 1a: Grundprinzip des Handlungsutilitarismus (4 Punkte)

**Erwartete Inhalte:**

**Kernaspekte für volle Punktzahl:**
1. **Konsequentialismus:** Handlungen werden ausschließlich nach ihren Folgen bewertet (1 Punkt)
2. **Nutzenmaximierung:** Ziel ist die Maximierung des Gesamtnutzens/Gesamtwohls (1 Punkt)
3. **Einzelfallbetrachtung:** Jede Handlung wird individuell in ihrer konkreten Situation bewertet (1 Punkt)
4. **Entscheidungskriterium:** Die Handlung ist richtig, die den größten Nutzen für die größte Anzahl bewirkt (1 Punkt)

**Musterlösung:**

Der Handlungsutilitarismus ist eine konsequentialistische Ethik, die Handlungen ausschließlich nach ihren Folgen bewertet. Das Grundprinzip lautet: Eine Handlung ist dann moralisch richtig, wenn sie in der konkreten Situation den größtmöglichen Nutzen bzw. das größte Gesamtwohl für alle Betroffenen bewirkt. Dabei wird jede Handlung einzeln betrachtet und durch eine systematische Abwägung aller positiven und negativen Konsequenzen beurteilt. Der Handlungsutilitarist fragt: "Welche Handlungsoption führt hier und jetzt zum besten Gesamtergebnis?"

**Bewertungshinweise:**
- 4 Punkte: Alle vier Kernaspekte klar dargestellt
- 3 Punkte: 3 Kernaspekte behandelt, kleinere Ungenauigkeiten
- 2 Punkte: 2 Kernaspekte erkennbar, aber Lücken
- 1 Punkt: Grundverständnis ansatzweise erkennbar
- 0 Punkte: Grundprinzip nicht verstanden oder falsch dargestellt

---

### Aufgabe 1b: Anwendung auf das Gedankenexperiment (8 Punkte)

**Erwartete Inhalte:**

**Kernaspekte für volle Punktzahl:**

1. **Systematische Konsequenzenanalyse (3 Punkte):**

   **Algorithmus A (Minimiere Todesopfer):**
   - Positiv: 1 Toter statt 5 → 4 Leben gerettet
   - Negativ: 1 regelkonformer Fußgänger wird getötet
   - Negativ: Fahrgast wird leicht verletzt

   **Algorithmus B (Schütze Regelkonforme):**
   - Positiv: Regelkonformer Fußgänger überlebt
   - Positiv: Fahrgast bleibt unverletzt
   - Negativ: 5 Todesfälle (regelwidrige Fußgänger)

2. **Nutzenkalkulation und Entscheidung (3 Punkte):**
   - Klare Empfehlung für **Algorithmus A**
   - Begründung: 1 Toter < 5 Tote (Gesamtnutzen ist höher)
   - Handlungsutilitarist zählt jeden Menschen gleich (Verschulden ist für Nutzenkalkulation irrelevant)
   - Das Ergebnis von 4 geretteten Leben überwiegt deutlich

3. **Kritische Reflexion der Position (2 Punkte):**
   - Erkenntnis, dass Verschulden/Regelkonformität für Handlungsutilitaristen keine Rolle spielt
   - Nur das Gesamtergebnis (Anzahl Toter/Verletzter) zählt
   - Erwähnung, dass diese Kalkulation in jedem Einzelfall neu durchgeführt wird

**Musterlösung:**

Ein Handlungsutilitarist würde **Algorithmus A** empfehlen (Minimierung der Gesamtzahl der Todesopfer).

**Begründung:** Der Handlungsutilitarismus bewertet ausschließlich die Konsequenzen und fragt: "Welche Option führt zum größten Gesamtwohl?" In diesem Fall ist die Bilanz eindeutig:

- **Algorithmus A:** 1 Todesopfer, 1 leicht Verletzter → 4 Leben gerettet im Vergleich zu Option B
- **Algorithmus B:** 5 Todesopfer, 0 Verletzte

Aus handlungsutilitaristischer Sicht ist Algorithmus A moralisch geboten, weil er den Gesamtschaden minimiert. Das Verschulden der Beteiligten (regelwidrig vs. regelkonform) spielt keine Rolle für die utilitaristische Kalkulation – jedes Menschenleben zählt gleich viel. Die Tatsache, dass die fünf Fußgänger die Straße regelwidrig überquert haben, ändert nichts daran, dass ihr Tod einen erheblichen Schaden darstellt. Der Tod eines Menschen (auch wenn regelkonform) ist ein geringerer Gesamtschaden als der Tod von fünf Menschen (auch wenn regelwidrig).

Die leichte Verletzung des Fahrgasts ist zwar negativ, wiegt aber deutlich weniger schwer als vier zusätzliche Todesfälle. Der Handlungsutilitarist würde argumentieren: "Es ist besser, einen unschuldigen Menschen zu opfern und einen leicht zu verletzen, als fünf Menschen sterben zu lassen."

**Bewertungshinweise:**
- 8 Punkte: Alle drei Kernaspekte vollständig und korrekt, klare systematische Argumentation
- 6-7 Punkte: Hauptargumentation korrekt, kleinere Lücken oder Ungenauigkeiten
- 4-5 Punkte: Grundlegende Anwendung erkennbar, aber wesentliche Aspekte fehlen oder unklar
- 2-3 Punkte: Ansätze vorhanden, aber erhebliche Fehler in der Argumentation
- 0-1 Punkte: Kaum Verständnis der Anwendung erkennbar

**Häufige Fehler:**
- Schüler gewichten Verschulden/Regelkonformität (das wäre regelutilitaristisch!)
- Schüler berücksichtigen nicht alle Konsequenzen systematisch
- Falsche Empfehlung für Algorithmus B mit handlungsutilitaristischer Begründung (Widerspruch!)

---

## Aufgabe 2: Analyse aus regelutilitaristischer Perspektive (12 Punkte)

### Aufgabe 2a: Grundprinzip des Regelutilitarismus (4 Punkte)

**Erwartete Inhalte:**

**Kernaspekte für volle Punktzahl:**
1. **Regelfokus statt Handlungsfokus:** Nicht die einzelne Handlung, sondern die zugrundeliegende Regel wird bewertet (1 Punkt)
2. **Langfristige Nutzenmaximierung:** Ziel ist das größte Gesamtwohl durch Befolgung von Regeln, die langfristig den größten Nutzen stiften (1 Punkt)
3. **Universelle Regeln:** Welche Regeln würden, wenn allgemein befolgt, das größte Gesamtwohl bewirken? (1 Punkt)
4. **Zentraler Unterschied zum Handlungsutilitarismus:** Einzelne Handlung kann suboptimal sein, aber Regel ist optimal (1 Punkt)

**Musterlösung:**

Der Regelutilitarismus bewertet nicht die einzelne Handlung, sondern die zugrundeliegende Regel nach ihren Konsequenzen. Das Grundprinzip lautet: Eine Handlung ist moralisch richtig, wenn sie einer Regel folgt, die – wenn allgemein befolgt – langfristig den größten Nutzen für alle bewirkt. Der zentrale Unterschied zum Handlungsutilitarismus liegt darin, dass nicht jede Handlung individuell kalkuliert wird, sondern man fragt: "Welche allgemeine Regel sollte in solchen Situationen gelten, um langfristig das größte Gesamtwohl zu befördern?"

**Bewertungshinweise:**
- 4 Punkte: Alle vier Kernaspekte klar dargestellt, Unterschied zum Handlungsutilitarismus deutlich
- 3 Punkte: 3 Kernaspekte behandelt, Unterschied erkennbar
- 2 Punkte: Grundverständnis vorhanden, aber Unterschied unklar
- 1 Punkt: Ansätze erkennbar, erhebliche Lücken
- 0 Punkte: Grundprinzip nicht verstanden oder mit Handlungsutilitarismus verwechselt

---

### Aufgabe 2b: Anwendung auf das Gedankenexperiment (8 Punkte)

**Erwartete Inhalte:**

**Kernaspekte für volle Punktzahl:**

1. **Identifikation relevanter Regeln (3 Punkte):**
   - Regel 1: "Schütze Personen, die sich regelkonform verhalten"
   - Regel 2: "Technische Systeme sollen vorhersehbar und vertrauenswürdig sein"
   - Regel 3: "Hersteller haben Fürsorgepflicht gegenüber Kunden/Fahrgästen"
   - Regel 4: "Verletze nicht aktiv unbeteiligte, regelkonforme Personen"

2. **Begründung der langfristigen Nützlichkeit dieser Regeln (3 Punkte):**
   - Wenn regelwidriges Verhalten geschützt wird, schwindet Anreiz zu regelkonformem Verhalten
   - Wenn Fahrgäste nicht geschützt werden, sinkt Vertrauen in autonome Fahrzeuge → weniger Akzeptanz → weniger Leben gerettet langfristig
   - Vorhersehbarkeit schafft Vertrauen und ermöglicht soziale Koordination
   - Schutz Unbeteiligter ist fundamentales Prinzip des Rechtsstaats

3. **Entscheidung und Gesamtargumentation (2 Punkte):**
   - Klare Empfehlung für **Algorithmus B**
   - Auch wenn im Einzelfall mehr Menschen sterben, ist die Regel langfristig nützlicher

**Musterlösung:**

Ein Regelutilitarist würde **Algorithmus B** empfehlen (Schutz regelkonformer Personen und des Fahrgasts).

**Begründung:** Der Regelutilitarismus fragt nicht, was in diesem einen Fall das beste Ergebnis liefert, sondern welche allgemeine Regel langfristig den größten Nutzen stiftet. Hier sind mehrere Regeln relevant:

**1. Regel: "Schütze Personen, die sich regelkonform verhalten"**
Wenn autonome Fahrzeuge systematisch regelkonforme Personen opfern, um regelwidrig handelnde Personen zu retten, entstehen problematische langfristige Konsequenzen:
- Der Anreiz zu regelkonformem Verhalten schwindet
- Menschen fühlen sich bestraft, wenn sie sich an Regeln halten
- Das Vertrauen in die Verkehrsordnung erodiert
- Langfristig führt dies zu mehr Chaos und mehr Unfällen

**2. Regel: "Technische Systeme sollen Kunden/Fahrgäste schützen"**
Wenn bekannt wird, dass autonome Fahrzeuge ihre Insassen opfern, um andere zu retten:
- Menschen werden diese Fahrzeuge meiden
- Geringere Akzeptanz autonomer Fahrzeuge
- Langfristig werden weniger Leben durch die Technologie gerettet (da weniger Menschen sie nutzen)
- Das größere Potenzial autonomer Fahrzeuge (Reduktion von 90% aller Unfälle) wird nicht ausgeschöpft

**3. Regel: "Verletze nicht aktiv Unbeteiligte"**
Der regelkonforme Fußgänger auf dem Gehweg ist völlig unbeteiligt an der gefährlichen Situation. Ihn aktiv zu opfern verletzt ein fundamentales ethisches Prinzip, das langfristig für soziales Vertrauen essenziell ist.

**Fazit:** Auch wenn im konkreten Einzelfall mehr Menschen sterben (5 statt 1), ist Algorithmus B regelutilitaristisch geboten. Die Befolgung der Regeln "Schütze Regelkonforme", "Schütze Kunden" und "Verletze nicht aktiv Unbeteiligte" führt langfristig zu mehr Vertrauen, mehr regelkonformem Verhalten und größerer Akzeptanz lebensrettender Technologie – und damit zum größeren Gesamtwohl.

**Bewertungshinweise:**
- 8 Punkte: Alle drei Kernaspekte vollständig, überzeugende Argumentation für langfristige Nützlichkeit
- 6-7 Punkte: Hauptargumentation korrekt, mindestens 2 Regeln identifiziert und begründet
- 4-5 Punkte: Grundlegende Anwendung erkennbar, aber Regeln nur oberflächlich behandelt
- 2-3 Punkte: Ansätze vorhanden, aber erhebliche Lücken in der Argumentation
- 0-1 Punkte: Regelutilitaristische Perspektive nicht verstanden

**Häufige Fehler:**
- Schüler empfehlen Algorithmus A (Verwechslung mit Handlungsutilitarismus!)
- Regeln werden genannt, aber langfristige Nützlichkeit nicht erklärt
- Fokus nur auf den Einzelfall statt auf langfristige Folgen der Regelbefolgung

---

## Aufgabe 3: Vergleichende Analyse und kritische Bewertung (15 Punkte)

### Aufgabe 3a: Vergleich der beiden Ansätze (7 Punkte)

**Erwartete Inhalte:**

**Kernaspekte für volle Punktzahl:**

1. **Unterschiedliche Entscheidungen (2 Punkte):**
   - Handlungsutilitarismus: Algorithmus A (minimiere Todesopfer im Einzelfall)
   - Regelutilitarismus: Algorithmus B (befolge Regeln, die langfristig nützlich sind)

2. **Zentraler Konflikt (3 Punkte):**
   - Kurzfristige vs. langfristige Optimierung
   - Einzelfall-Kalkulation vs. Regelbefolgung
   - Quantitative Maximierung vs. qualitative Prinzipien (Schutz Regelkonformer)

3. **Erklärung der Divergenz (2 Punkte):**
   - Handlungsutilitarismus: Nur unmittelbare Folgen dieser einen Handlung zählen
   - Regelutilitarismus: Berücksichtigt indirekte, langfristige Folgen der Regelbefolgung (Vertrauen, Anreizstrukturen, gesellschaftliche Akzeptanz)

**Musterlösung:**

Die beiden utilitaristischen Ansätze führen in diesem Fall zu **entgegengesetzten Empfehlungen**:

- **Handlungsutilitarismus empfiehlt Algorithmus A:** Minimiere die Todesopfer im konkreten Einzelfall (1 Toter statt 5)
- **Regelutilitarismus empfiehlt Algorithmus B:** Befolge die Regel "Schütze Regelkonforme und Kunden", auch wenn im Einzelfall mehr Menschen sterben

**Der zentrale Konflikt** liegt in der Zeitperspektive und dem Fokus:

Der **Handlungsutilitarismus** betrachtet nur die unmittelbaren Konsequenzen dieser einen Entscheidung: "Wie viele Menschen sterben in diesem Moment?" Die Antwort ist klar: 1 ist besser als 5.

Der **Regelutilitarismus** betrachtet die langfristigen Konsequenzen der Regelbefolgung: "Was passiert, wenn diese Regel in Millionen von Fahrzeugen weltweit angewendet wird?" Hier ergibt sich ein komplexeres Bild:
- Wenn Algorithmus A verwendet wird: Vertrauen in autonome Fahrzeuge sinkt, Akzeptanz sinkt, langfristig werden weniger Leben gerettet
- Wenn Algorithmus B verwendet wird: Vertrauen bleibt erhalten, Regelkonformität wird gefördert, Technologie kann ihr Potenzial entfalten

**Warum die Divergenz?** Der Handlungsutilitarismus isoliert die Handlung von ihrem sozialen Kontext und fragt nur: "Was ist das beste Ergebnis jetzt?" Der Regelutilitarismus berücksichtigt, dass Handlungen in einem System von Erwartungen, Vertrauen und Anreizen stattfinden. Eine Handlung, die im Einzelfall suboptimal erscheint, kann Teil einer Regel sein, die langfristig das größte Gesamtwohl befördert.

**Bewertungshinweise:**
- 7 Punkte: Alle drei Kernaspekte vollständig und klar dargestellt, überzeugende Erklärung
- 5-6 Punkte: Unterschiede und Konflikt erkennbar, Erklärung teilweise vorhanden
- 3-4 Punkte: Grundlegende Unterschiede benannt, aber Erklärung oberflächlich
- 1-2 Punkte: Ansätze vorhanden, aber erhebliche Lücken
- 0 Punkte: Vergleich fehlt oder falsch

---

### Aufgabe 3b: Stärken und Schwächen beider Ansätze (8 Punkte)

**Erwartete Inhalte:**

**Je 2 Punkte pro Stärke/Schwäche (1 Punkt für Nennung, 1 Punkt für Erläuterung)**

**Handlungsutilitarismus:**

**Mögliche Stärken (2 Punkte für eine gut erläuterte):**
1. **Flexibilität:** Kann auf die Besonderheiten jeder Situation eingehen, keine starre Regelbefolgung
2. **Direkte Nutzenmaximierung:** Garantiert im Einzelfall das beste Ergebnis (4 Leben gerettet)
3. **Klarheit:** Einfache, transparente Kalkulation (zähle Tote und Verletzte)
4. **Effizienz:** Keine "verschwendeten" Leben aufgrund abstrakter Regeln

**Mögliche Schwächen (2 Punkte für eine gut erläuterte):**
1. **Ignoriert langfristige Folgen:** Berücksichtigt nicht, wie die Entscheidung Vertrauen, Anreize und Akzeptanz beeinflusst
2. **Instrumentalisierung von Personen:** Regelkonforme Person wird aktiv geopfert, obwohl sie alles richtig gemacht hat
3. **Vorhersehbarkeit fehlt:** Menschen können nicht wissen, ob sie geschützt werden, schafft Unsicherheit
4. **Verletzt Gerechtigkeitsintuition:** Regelwidrige Personen werden bevorzugt behandelt

**Regelutilitarismus:**

**Mögliche Stärken (2 Punkte für eine gut erläuterte):**
1. **Berücksichtigt langfristige Folgen:** Denkt über den Einzelfall hinaus (Vertrauen, Anreize, Akzeptanz)
2. **Fördert Vorhersehbarkeit:** Menschen können sich auf Regeln verlassen, schafft soziale Koordination
3. **Schützt fundamentale Prinzipien:** Regelkonformität, Schutz Unbeteiligter, Kundenvertrauen
4. **Pragmatisch:** Berücksichtigt, dass Technologie nur funktioniert, wenn Menschen ihr vertrauen

**Mögliche Schwächen (2 Punkte für eine gut erläuterte):**
1. **Suboptimal im Einzelfall:** 5 Menschen sterben statt 1, erscheint intuitiv falsch
2. **Regelstarrheit:** Kann nicht flexibel auf besondere Umstände reagieren
3. **Schwierige Regelfindung:** Welche Regeln sind langfristig optimal? Unklar und umstritten
4. **Rechtfertigungsproblem:** Schwer den Angehörigen der 5 Toten zu erklären, warum sie geopfert wurden

**Musterlösung (Beispiel):**

**Handlungsutilitarismus:**

**Stärke:** Der Handlungsutilitarismus maximiert den unmittelbaren Nutzen und rettet in diesem konkreten Fall 4 Leben (1 Toter statt 5). Diese direkte Nutzenmaximierung ist die zentrale Stärke: Im Einzelfall wird das objektiv beste Ergebnis erzielt.

**Schwäche:** Der Handlungsutilitarismus ignoriert die langfristigen sozialen Folgen seiner Entscheidung. Wenn Menschen wissen, dass autonome Fahrzeuge regelkonforme Personen opfern, um regelwidrige zu retten, schwindet das Vertrauen in die Technologie und die Verkehrsordnung. Dies könnte langfristig zu mehr Unfällen und weniger geretteten Leben führen – die Einzelfall-Optimierung ist also möglicherweise kontraproduktiv.

**Regelutilitarismus:**

**Stärke:** Der Regelutilitarismus berücksichtigt langfristige und indirekte Konsequenzen wie Vertrauen, Anreizstrukturen und Akzeptanz. Durch den Schutz regelkonformen Verhaltens und des Kundenvertrauens schafft er die Voraussetzungen dafür, dass autonome Fahrzeuge langfristig ihr volles Potenzial entfalten und Millionen von Leben retten können.

**Schwäche:** Im konkreten Einzelfall erscheint die regelutilitaristische Entscheidung kontraintuitiv und grausam: 5 Menschen sterben, um 1 zu retten. Diese Regelstarrheit kann im Einzelfall zu erheblichem Leid führen, das vermeidbar gewesen wäre. Die Rechtfertigung gegenüber den Betroffenen und ihren Angehörigen ist schwierig.

**Bewertungshinweise:**
- 8 Punkte: Alle 4 Stärken/Schwächen genannt UND gut erläutert (je 2 Punkte)
- 6-7 Punkte: 3-4 Aspekte gut behandelt oder alle 4 genannt aber teilweise schwach erläutert
- 4-5 Punkte: 2-3 Aspekte behandelt, Erläuterungen teilweise oberflächlich
- 2-3 Punkte: Nur wenige Aspekte, kaum Erläuterung
- 0-1 Punkte: Kaum relevante Inhalte

**Häufige Fehler:**
- Nur Nennung ohne Erläuterung
- Verwechslung der Ansätze
- Allgemeine Kritik am Utilitarismus statt spezifischer Stärken/Schwächen im Kontext dieses Falls

---

## Aufgabe 4: Eigene philosophisch begründete Position (6 Punkte)

**Erwartete Inhalte:**

**Kernaspekte für volle Punktzahl:**

1. **Klare Position (1 Punkt):**
   - Eindeutige Empfehlung für Algorithmus A oder B
   - Klare Präferenz für einen der beiden utilitaristischen Ansätze

2. **Philosophische Begründung (3 Punkte):**
   - Bezug auf die Argumente aus den vorherigen Aufgaben
   - Abwägung der Stärken und Schwächen
   - Erklärung, warum dieser Ansatz in diesem Fall überzeugender ist
   - Kohärente Argumentation

3. **Reflexionstiefe (2 Punkte):**
   - Eigenständige Gedankenführung erkennbar
   - Ggf. Erwähnung von Grenzen des gewählten Ansatzes
   - Ggf. Hinweis auf andere ethische Perspektiven (Deontologie, Tugendethik)
   - Kritisches Bewusstsein für Komplexität des Dilemmas

**Bewertungshinweise:**

Es gibt keine "richtige" Antwort – beide Positionen können mit 6 Punkten bewertet werden, wenn sie philosophisch fundiert begründet werden.

**Beispiel für Algorithmus A (Handlungsutilitarismus):**

"Ich würde Algorithmus A empfehlen, weil der Handlungsutilitarismus in diesem Fall überzeugender ist. Die Rettung von 4 zusätzlichen Menschenleben ist ein so erheblicher Nutzen, dass er langfristige Erwägungen überwiegt. Die regelutilitaristische Sorge um Vertrauen und Anreize ist zwar berechtigt, aber spekulativ: Es ist nicht sicher, dass die Akzeptanz autonomer Fahrzeuge sinkt. Hingegen ist sicher, dass im konkreten Fall 4 Menschen mehr sterben, wenn man Algorithmus B wählt. Zudem könnte man argumentieren, dass transparente Kommunikation ('Das Fahrzeug rettet die meisten Leben') das Vertrauen eher stärkt als schwächt. Die regelutilitaristische Position scheint mir zu sehr an abstrakten Prinzipien zu hängen und verliert den konkreten Menschen aus dem Blick."

**Beispiel für Algorithmus B (Regelutilitarismus):**

"Ich würde Algorithmus B empfehlen, weil der Regelutilitarismus die Komplexität des Problems besser erfasst. Es geht nicht nur um diesen einen Fall, sondern um Millionen von Entscheidungen in einem sozialen System. Wenn autonome Fahrzeuge nicht mehr vertrauenswürdig erscheinen oder regelwidriges Verhalten belohnen, könnte langfristig mehr Schaden entstehen als im Einzelfall verhindert wird. Der Schutz fundamentaler Prinzipien (Regelkonformität, Kundenschutz, Nicht-Instrumentalisierung Unbeteiligter) ist für das Funktionieren einer Gesellschaft essenziell. Auch aus einer deontologischen Perspektive wäre Algorithmus B vorzuziehen: Der regelkonforme Fußgänger hat ein Recht, nicht aktiv geopfert zu werden. Die handlungsutilitaristische Kalkulation erscheint mir zu mechanisch und ignoriert wichtige qualitative Unterschiede zwischen den Beteiligten."

**Bewertungshinweise:**
- 6 Punkte: Klare Position, überzeugende philosophische Begründung, Reflexionstiefe erkennbar
- 4-5 Punkte: Position und Begründung vorhanden, aber teilweise oberflächlich oder lückenhaft
- 2-3 Punkte: Position vorhanden, aber Begründung schwach oder wenig philosophisch
- 0-1 Punkte: Keine klare Position oder keine Begründung

**Wichtig:**
- Beide Positionen (A und B) sind gleichwertig bewertbar
- Entscheidend ist die Qualität der Argumentation, nicht die Richtung
- Eigenständiges Denken wird belohnt, auch wenn es vom "Lehrbuch" abweicht
- Ggf. Bonuspunkte für besonders originelle oder tiefgründige Argumente (im Rahmen der 6 Punkte)

---

## Gesamtbewertung

**Erreichte Punktzahl:** _____ / 45 Punkten

**Notenpunkte:** _____ (siehe Bewertungstabelle im Schülertest)

**Note:** _____

---

## Zusätzliche Korrekturhinweise

### Zeiteinteilung (zur Information)

- Aufgabe 1: ~12 Minuten (12 Punkte)
- Aufgabe 2: ~12 Minuten (12 Punkte)
- Aufgabe 3: ~15 Minuten (15 Punkte)
- Aufgabe 4: ~6 Minuten (6 Punkte)

Diese Zeiteinteilung ist eine Orientierung für durchschnittliche Schüler. Schnellere Schüler können früher fertig sein, langsamere benötigen ggf. etwas mehr Zeit.

### Häufige Fehlerquellen

1. **Verwechslung der beiden Ansätze:** Schüler beschreiben Handlungsutilitarismus bei Aufgabe 2 und umgekehrt
2. **Fehlende Anwendung:** Schüler bleiben zu abstrakt und beziehen sich nicht konkret auf das Gedankenexperiment
3. **Unvollständige Argumentation:** Nur ein Aspekt wird betrachtet, andere werden ignoriert
4. **Mangelnde Fachterminologie:** Umgangssprachliche statt philosophischer Begriffe
5. **Keine Begründung für eigene Position:** Nur Meinung ohne philosophische Fundierung

### Differenzierung

**Sehr gute Leistungen (13-15 Punkte):**
- Alle Aspekte vollständig und korrekt
- Überzeugende, kohärente Argumentation
- Eigenständige Reflexion erkennbar
- Präzise Fachsprache

**Gute Leistungen (10-12 Punkte):**
- Alle Aspekte behandelt, kleinere Lücken
- Solide Argumentation
- Fachsprache weitgehend korrekt

**Befriedigende Leistungen (7-9 Punkte):**
- Grundverständnis erkennbar
- Argumentation teilweise oberflächlich
- Fachsprache mit Lücken

**Ausreichende Leistungen (4-6 Punkte):**
- Ansätze vorhanden
- Erhebliche Lücken in Verständnis und Argumentation
- Fachsprache fehlerhaft

**Mangelhafte/Ungenügende Leistungen (0-3 Punkte):**
- Grundverständnis fehlt
- Kaum Argumentation
- Fachsprache nicht vorhanden

---

**Datum der Korrektur:** ____________

**Unterschrift Lehrkraft:** ______________________

**Anmerkungen:**

_____________________________________________________________________________________

_____________________________________________________________________________________

_____________________________________________________________________________________
