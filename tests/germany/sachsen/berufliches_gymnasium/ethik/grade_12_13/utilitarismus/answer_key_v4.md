---
title: "Erwartungshorizont Version 4: Handlungsutilitarismus vs. Regelutilitarismus"
subject: Ethik/Philosophie
country: Germany
bundesland: Sachsen
school_type: Berufliches Gymnasium
klassenstufe: 12/13
type: Lösungsvorschlag
version: 4.0
date_created: 2025-11-20
---

# Erwartungshorizont: Stundenarbeit Version 4
## Handlungsutilitarismus vs. Regelutilitarismus

**Berufliches Gymnasium Sachsen**
**Fach:** Ethik/Philosophie
**Klassenstufe:** 12/13
**Gesamtpunktzahl:** 40 Punkte

---

## Gedankenexperiment: Die Programmierung autonomer Fahrzeuge

**Dilemma:** Ein autonomes Fahrzeug kann entweder fünf Kinder töten (Option A: geradeaus) oder den eigenen Passagier opfern, um die Kinder zu retten (Option B: ausweichen auf Gehweg/Mauer).

---

## Aufgabe 1: Handlungsutilitaristische Analyse (12 Punkte)

### a) Grundprinzip des Handlungsutilitarismus (4 Punkte)

**Erwartete Inhalte:**

**Volle Punktzahl (4 Punkte):**
- Der Handlungsutilitarismus bewertet jede einzelne Handlung nach ihren konkreten Konsequenzen
- Zentrale Maxime: "Handle so, dass die größtmögliche Menge an Glück/Nutzen für die größtmögliche Anzahl von Menschen entsteht"
- Entscheidungskriterium: Abwägung des Gesamtnutzens bzw. der Gesamtsumme an Glück/Leid, die durch die Handlung in dieser spezifischen Situation entsteht
- Es gibt keine festen Regeln; jede Situation wird individuell nach dem Nutzenkalkül bewertet

**Teilpunkte (2-3 Punkte):**
- Grundidee der Nutzenmaximierung genannt
- Fokus auf Konsequenzen erkannt
- Einzelne Aspekte fehlen oder sind ungenau

**Geringe Punktzahl (0-1 Punkte):**
- Nur oberflächliche oder fehlerhafte Darstellung
- Verwechslung mit Regelutilitarismus

---

### b) Anwendung auf das Gedankenexperiment (8 Punkte)

**Erwartete Inhalte:**

**Volle Punktzahl (7-8 Punkte):**

**Empfehlung:** Ein Handlungsutilitarist würde empfehlen, das Fahrzeug so zu programmieren, dass es **Option B wählt** (ausweichen, um die fünf Kinder zu retten, auch wenn der Passagier stirbt).

**Begründung:**
- **Nutzenkalkül:** Tod von 1 Person (Passagier) vs. Tod von 5 Personen (Kinder)
- **Quantitative Abwägung:** 5 gerettete Leben wiegen schwerer als 1 verlorenes Leben
- **Gesamtnutzen:** Option B produziert das größere Gesamtwohl (4 Leben mehr gerettet als verloren)
- **Keine Sonderstellung:** Der Handlungsutilitarismus macht keinen moralisch relevanten Unterschied zwischen dem Passagier und den Kindern – alle Menschenleben zählen gleich
- **Situationsspezifisch:** Diese Berechnung gilt nur für diese konkrete Situation (5 gegen 1)

**Mögliche Zusatzpunkte für:**
- Diskussion weiterer Folgen (z.B. Leid der Angehörigen, aber auch hier: 5 Familien > 1 Familie)
- Klare Darstellung, dass andere Faktoren (Alter, Besitzverhältnis) moralisch irrelevant sind

**Mittlere Punktzahl (4-6 Punkte):**
- Richtige Empfehlung (Option B), aber Begründung lückenhaft
- Nutzenkalkül erkannt, aber nicht systematisch durchgeführt
- Fehlende Berücksichtigung der Gleichwertigkeit aller Leben

**Geringe Punktzahl (0-3 Punkte):**
- Falsche Empfehlung ohne überzeugende utilitaristische Begründung
- Verwechslung mit anderen ethischen Ansätzen
- Nur oberflächliche Analyse

---

## Aufgabe 2: Regelutilitaristische Analyse (12 Punkte)

### a) Grundprinzip des Regelutilitarismus (4 Punkte)

**Erwartete Inhalte:**

**Volle Punktzahl (4 Punkte):**
- Der Regelutilitarismus bewertet nicht einzelne Handlungen, sondern **allgemeine Regeln** nach ihrem Nutzen
- Eine Handlung ist richtig, wenn sie einer Regel folgt, deren **allgemeine Befolgung** den größten Gesamtnutzen für die Gesellschaft bewirkt
- **Unterschied zum Handlungsutilitarismus:** Nicht die Konsequenzen der Einzelhandlung, sondern die Konsequenzen der allgemeinen Regelbefolgung sind entscheidend
- Langfristige, gesellschaftsweite Perspektive statt situationsspezifischer Kalkulation

**Teilpunkte (2-3 Punkte):**
- Fokus auf Regeln statt Einzelhandlungen genannt
- Unterschied zum Handlungsutilitarismus erkannt
- Einzelne Aspekte fehlen oder ungenau

**Geringe Punktzahl (0-1 Punkte):**
- Nur oberflächliche Darstellung
- Verwechslung mit Handlungsutilitarismus
- Keine klare Abgrenzung

---

### b) Anwendung auf das Gedankenexperiment (8 Punkte)

**Erwartete Inhalte:**

**Volle Punktzahl (7-8 Punkte):**

**Empfehlung:** Ein Regelutilitarist würde wahrscheinlich empfehlen, das Fahrzeug so zu programmieren, dass es **Option A wählt** (den Passagier schützt, auch wenn dadurch die fünf Kinder sterben).

**Begründung durch relevante Regeln:**

**Regel 1: "Autonome Fahrzeuge sollen die Sicherheit ihrer Passagiere priorisieren"**
- **Langfristiger Nutzen:** Wenn Menschen darauf vertrauen können, dass das Fahrzeug sie schützt, werden sie autonome Fahrzeuge nutzen
- **Gesellschaftlicher Gesamtnutzen:** Breite Akzeptanz autonomer Fahrzeuge führt zu weniger Verkehrstoten insgesamt (da menschliche Fahrfehler die Hauptunfallursache sind)
- **Vertrauen:** Ohne diese Regel würde niemand ein autonomes Fahrzeug kaufen, das ihn im Notfall opfert

**Regel 2: "Hersteller/Verkäufer haben besondere Schutzpflichten gegenüber Kunden"**
- Käufer haben eine vertragliche und moralische Erwartung, dass das Produkt ihre Sicherheit priorisiert
- Verletzung dieser Erwartung würde das gesellschaftliche Vertrauen in Technologie untergraben

**Regel 3: "Niemand soll durch ein Produkt, das er rechtmäßig nutzt, intentional geopfert werden"**
- Eine allgemeine Regel, die erlaubt, Kunden zu opfern, würde zu erheblichem gesellschaftlichem Schaden führen

**Langfristige Perspektive:**
- Auch wenn in dieser einen Situation 5 Leben verloren gehen, bewirkt die allgemeine Befolgung der "Passagierschutz"-Regel langfristig mehr Gesamtnutzen:
  - Mehr Verkaufszahlen → mehr autonome Fahrzeuge auf den Straßen
  - Weniger Unfälle insgesamt durch Eliminierung menschlicher Fehler
  - Gesellschaftliche Akzeptanz neuer Technologien

**Mittlere Punktzahl (4-6 Punkte):**
- Relevante Regeln genannt, aber Begründung des langfristigen Nutzens fehlt
- Vertrauen/Akzeptanz erkannt, aber nicht systematisch ausgeführt
- Verbindung zur gesellschaftlichen Perspektive unklar

**Geringe Punktzahl (0-3 Punkte):**
- Keine klaren Regeln formuliert
- Verwechslung mit Handlungsutilitarismus
- Nur oberflächliche Analyse

---

## Aufgabe 3: Vergleichende Bewertung (10 Punkte)

### a) Unterschiedliche Entscheidungen und zentraler Konflikt (5 Punkte)

**Erwartete Inhalte:**

**Volle Punktzahl (5 Punkte):**

**Unterschiedliche Entscheidungen:**
- **Handlungsutilitarismus:** Option B (Passagier opfern, Kinder retten) – wegen unmittelbarer Nutzenmaximierung (5 > 1)
- **Regelutilitarismus:** Option A (Passagier schützen) – wegen langfristigem gesellschaftlichem Nutzen der "Passagierschutz"-Regel

**Zentraler Konflikt:**
- **Zeitliche Perspektive:** Kurzfristige, situationsspezifische Nutzenmaximierung (HU) vs. langfristige, gesellschaftsweite Nutzenmaximierung (RU)
- **Einzelfall vs. Regel:** Direkte Folgen dieser einen Handlung (HU) vs. Folgen der allgemeinen Befolgung einer Regel (RU)
- **Zahlen vs. Vertrauen:** Unmittelbare Lebensrettung durch Zahlen (HU) vs. gesellschaftliches Vertrauen und Akzeptanz (RU)
- **Konsequenz:** In diesem Fall führt die Fokussierung auf verschiedene Ebenen (Einzelhandlung vs. Regel) zu entgegengesetzten Empfehlungen

**Teilpunkte (3-4 Punkte):**
- Unterschiedliche Empfehlungen korrekt identifiziert
- Konflikt ansatzweise erkannt, aber nicht präzise formuliert

**Geringe Punktzahl (0-2 Punkte):**
- Unterschiede unklar oder falsch dargestellt
- Kein echter Konflikt herausgearbeitet

---

### b) Stärken und Schwächen (5 Punkte)

**Erwartete Inhalte:**

**Volle Punktzahl (5 Punkte):**

**Handlungsutilitarismus:**

**Stärke (in diesem Fall):**
- **Intuitive Plausibilität:** Die Rettung von 5 Leben statt 1 erscheint unmittelbar rational und fair
- **Klare Berechenbarkeit:** Eindeutiges Nutzenkalkül (5 > 1) ohne komplizierte Regelabwägungen
- **Flexibilität:** Kann auf die spezifischen Umstände der Situation reagieren

**Schwäche (in diesem Fall):**
- **Ignoriert wichtige soziale Faktoren:** Vertrauen, Erwartungen, Käuferrechte werden nicht berücksichtigt
- **Kontraintuitiv:** Menschen würden kein Fahrzeug kaufen, das sie im Notfall opfert – der HU ignoriert diese Realität
- **Kurzfristig gedacht:** Übersieht langfristige gesellschaftliche Konsequenzen (Ablehnung der Technologie → mehr Verkehrstote insgesamt)

**Regelutilitarismus:**

**Stärke (in diesem Fall):**
- **Berücksichtigt gesellschaftliche Faktoren:** Vertrauen, Akzeptanz, langfristige Technologieentwicklung werden einbezogen
- **Praktikabilität:** Liefert eine klare, allgemein anwendbare Regel für Programmierer
- **Realistische Folgenabschätzung:** Erkennt, dass ohne Passagierschutz die Technologie abgelehnt würde

**Schwäche (in diesem Fall):**
- **Kontraintuitiv im Einzelfall:** Im konkreten Moment sterben 5 Menschen statt 1 – das erscheint schwer zu rechtfertigen
- **Regelkonflikt:** Andere Regeln (z.B. "Schütze Unschuldige", "Rette möglichst viele Leben") könnten ebenfalls gerechtfertigt werden
- **Kaltherzig:** Die fünf Kinder und ihre Familien werden für ein abstraktes gesellschaftliches Ziel geopfert

**Bewertung:**
- Je 1,25 Punkte pro Stärke/Schwäche (4 × 1,25 = 5 Punkte)
- Teilpunkte für teilweise richtige oder unvollständige Antworten
- Abzüge für faktische Fehler oder Verwechslungen

---

## Aufgabe 4: Eigene philosophisch begründete Position (6 Punkte)

**Erwartete Inhalte:**

**Volle Punktzahl (5-6 Punkte):**

Die Schüler können beide Positionen verteidigen, solange die Argumentation philosophisch fundiert ist.

**Mögliche Position 1: Pro Handlungsutilitarismus (Option B – Kinder retten)**

- Im konkreten Moment zählt das unmittelbare Ergebnis: 5 Leben sind mehr wert als 1 Leben
- Der Passagier hat sich freiwillig in ein autonomes Fahrzeug begeben und akzeptiert damit die Risiken moderner Technologie
- Moralisch sind alle Menschenleben gleichwertig; der Besitzstatus ("es ist mein Auto") rechtfertigt keine Sonderbehandlung
- Die langfristigen Bedenken des Regelutilitarismus sind spekulativ; die unmittelbare Lebensrettung ist real und sicher

**Mögliche Position 2: Pro Regelutilitarismus (Option A – Passagier schützen)**

- Die gesellschaftliche Akzeptanz autonomer Fahrzeuge ist entscheidend für den langfristigen Gesamtnutzen
- Ohne Vertrauen in die Technologie werden Menschen weiterhin selbst fahren → mehr Unfälle insgesamt
- Der Schutz vertraglicher Erwartungen und Käuferrechte ist ein wichtiges moralisches Prinzip
- Einzelfallentscheidungen (HU) können zu moralisch inkonsistenten und gesellschaftlich schädlichen Ergebnissen führen

**Mögliche Position 3: Kritik beider Ansätze / Alternative Perspektiven**

- Beide utilitaristischen Ansätze ignorieren deontologische Aspekte (z.B. das Verbot, Menschen als Mittel zu instrumentalisieren)
- Tugendethische Perspektive: Welche Haltung/Tugend würde eine weise Person in dieser Situation zeigen?
- Diskursethik: Die Entscheidung sollte durch gesellschaftlichen Dialog und demokratische Prozesse gefällt werden, nicht allein durch utilitaristische Berechnung

**Bewertungskriterien:**
- **Klare Position:** 1 Punkt
- **Philosophische Begründung:** 2-3 Punkte
- **Bezug zu den beiden Ansätzen:** 1 Punkt
- **Eigenständiges Denken / kritische Reflexion:** 1-2 Punkte

**Mittlere Punktzahl (3-4 Punkte):**
- Position genannt, aber Begründung oberflächlich
- Bezug zu utilitaristischen Ansätzen vorhanden, aber schwach
- Wenig eigenständiges Denken

**Geringe Punktzahl (0-2 Punkte):**
- Keine klare Position
- Fehlende oder fehlerhafte philosophische Begründung
- Kein Bezug zu den gelernten Konzepten

---

## Zusammenfassung der Musterlösung

| Aufgabe | Erwartete Antwort | Punkte |
|---------|-------------------|--------|
| 1a | Grundprinzip Handlungsutilitarismus: Einzelhandlung, Nutzenmaximierung, keine festen Regeln | 4 |
| 1b | **Option B** (Kinder retten): 5 Leben > 1 Leben, Gleichwertigkeit aller Menschen | 8 |
| 2a | Grundprinzip Regelutilitarismus: Regeln statt Einzelhandlungen, langfristiger Nutzen | 4 |
| 2b | **Option A** (Passagier schützen): Vertrauen, Akzeptanz, langfristiger gesellschaftlicher Nutzen | 8 |
| 3a | HU→Option B, RU→Option A; Konflikt: Einzelfall vs. Regel, kurzfristig vs. langfristig | 5 |
| 3b | Je 1 Stärke + 1 Schwäche für HU und RU, bezogen auf den konkreten Fall | 5 |
| 4 | Eigene Position, philosophisch begründet, mit Bezug zu HU/RU | 6 |
| **Gesamt** | | **40** |

---

## Hinweise zur Bewertung

**Allgemeine Kriterien:**
- **Fachsprache:** Konsequente Verwendung der Begriffe "Handlungsutilitarismus", "Regelutilitarismus", "Nutzenkalkül", "Gesamtwohl", "Konsequenzen"
- **Argumentationsstruktur:** Klare Begründungsketten, keine bloßen Behauptungen
- **Philosophische Tiefe:** Über oberflächliche Aussagen hinausgehende Reflexion
- **Eigenständigkeit:** Keine bloße Wiederholung von Lehrbuchdefinitionen, sondern Anwendung auf den konkreten Fall

**Häufige Fehler:**
- Verwechslung von Handlungs- und Regelutilitarismus
- Einbringen nicht-utilitaristischer Argumente (z.B. Rechte, Pflichten) ohne diese als solche zu kennzeichnen
- Fehlende Unterscheidung zwischen kurzfristigen und langfristigen Konsequenzen
- Moralische Intuition statt philosophischer Begründung

**Notenschlüssel:** Siehe Bewertungsskala in der Stundenarbeit (15-Punkte-System Sachsen Oberstufe)

---

**Ende des Erwartungshorizonts**
